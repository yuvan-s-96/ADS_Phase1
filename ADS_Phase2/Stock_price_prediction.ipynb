{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-Fpp7aLNBKA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load historical MSFT stock data\n",
        "data = pd.read_csv(\"/content/MSFT.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant columns\n",
        "data = data[['Date', 'Close', 'Volume']]\n",
        "\n",
        "# Ensure the 'Date' column is in datetime format\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "\n",
        "# Set 'Date' as the index\n",
        "data.set_index('Date', inplace=True)\n",
        "\n",
        "# Create lag features (optional, for time series data)\n",
        "data['Close_Lag1'] = data['Close'].shift(1)\n",
        "data.dropna(inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkLbDhlkNQp9",
        "outputId": "decdbb2b-f7f6-4713-c870-fca0ff79cc8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-37d9189e0fc4>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Date'] = pd.to_datetime(data['Date'])\n",
            "<ipython-input-2-37d9189e0fc4>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Close_Lag1'] = data['Close'].shift(1)\n",
            "<ipython-input-2-37d9189e0fc4>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.dropna(inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data[['Close_Lag1', 'Volume']]  # Features\n",
        "y = data['Close']  # Target variable\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "zChT1AihNSdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "3Vq1B-0sNVmk",
        "outputId": "3e0632c3-b91a-4437-f8c2-9b70858ee9a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "print(f\"MAE: {mae}\")\n",
        "print(f\"RMSE: {rmse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv9Bxg5jNXrM",
        "outputId": "2faf92ed-9ac5-4e3f-9762-697cc87f23db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.3617502213217889\n",
            "RMSE: 0.690037500741847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prediction for a new data point\n",
        "new_data_point = pd.DataFrame({'Close_Lag1': [300], 'Volume': [50000000]})\n",
        "predicted_price = model.predict(new_data_point)\n",
        "print(f\"Predicted Price: {predicted_price[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEQoLqiMNZms",
        "outputId": "fba88a43-b00e-427f-ca3d-f8bc0bbed4b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Price: 300.28569705264243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Step 1: Load historical MSFT stock data\n",
        "data = pd.read_csv(\"/content/MSFT.csv\")\n",
        "\n",
        "# Step 2: Data Preprocessing\n",
        "data = data[['Date', 'Close', 'Volume']]\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data.set_index('Date', inplace=True)\n",
        "data['Close_Lag1'] = data['Close'].shift(1)\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Step 3: Split the Data\n",
        "X = data[['Close_Lag1', 'Volume']]\n",
        "y = data['Close']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Build and Train a Random Forest Model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
        "rf_rmse = sqrt(mean_squared_error(y_test, rf_pred))\n",
        "\n",
        "print(f\"MAE: {rf_mae}\")\n",
        "print(f\"RMSE: {rf_rmse}\")\n",
        "\n",
        "# Step 6: Make Predictions\n",
        "new_data_point = pd.DataFrame({'Close_Lag1': [300], 'Volume': [50000000]})\n",
        "rf_predicted_price = rf_model.predict(new_data_point)\n",
        "print(f\"Random Forest Predicted Price: {rf_predicted_price[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEEq4HkkNi9k",
        "outputId": "888dd6b5-103b-48cb-8e91-dabcaad29bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.392897397167157\n",
            "RMSE: 0.7448300987795577\n",
            "Random Forest Predicted Price: 157.27600016999975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape the data for LSTM (samples, time steps, features)\n",
        "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
        "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
        "\n",
        "# Build and train the LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, activation='relu', input_shape=(1, X_train_scaled.shape[1])))\n",
        "lstm_model.add(Dense(1))\n",
        "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "lstm_model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf1G1f4WN3Ys",
        "outputId": "8feafffe-6c0b-4429-da0e-2f1e5ab28463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "214/214 [==============================] - 2s 3ms/step - loss: 1575.5159\n",
            "Epoch 2/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 1350.0437\n",
            "Epoch 3/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 907.2581\n",
            "Epoch 4/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 559.8977\n",
            "Epoch 5/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 368.0958\n",
            "Epoch 6/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 228.2397\n",
            "Epoch 7/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 125.5877\n",
            "Epoch 8/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 59.9327\n",
            "Epoch 9/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 25.1942\n",
            "Epoch 10/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 10.7963\n",
            "Epoch 11/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 5.4904\n",
            "Epoch 12/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 3.4228\n",
            "Epoch 13/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 2.3911\n",
            "Epoch 14/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 1.7125\n",
            "Epoch 15/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 1.3035\n",
            "Epoch 16/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 1.0397\n",
            "Epoch 17/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 0.8671\n",
            "Epoch 18/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 0.7570\n",
            "Epoch 19/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.6874\n",
            "Epoch 20/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.6415\n",
            "Epoch 21/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.6106\n",
            "Epoch 22/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.5869\n",
            "Epoch 23/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.5680\n",
            "Epoch 24/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.5535\n",
            "Epoch 25/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.5436\n",
            "Epoch 26/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.5349\n",
            "Epoch 27/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.5322\n",
            "Epoch 28/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.5264\n",
            "Epoch 29/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 0.5255\n",
            "Epoch 30/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 0.5220\n",
            "Epoch 31/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 0.5176\n",
            "Epoch 32/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.5184\n",
            "Epoch 33/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.5173\n",
            "Epoch 34/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.5168\n",
            "Epoch 35/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.5131\n",
            "Epoch 36/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.5117\n",
            "Epoch 37/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 0.5059\n",
            "Epoch 38/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 0.5070\n",
            "Epoch 39/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 0.5083\n",
            "Epoch 40/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.5020\n",
            "Epoch 41/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4982\n",
            "Epoch 42/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.5067\n",
            "Epoch 43/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.5017\n",
            "Epoch 44/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4950\n",
            "Epoch 45/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.4925\n",
            "Epoch 46/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4932\n",
            "Epoch 47/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4909\n",
            "Epoch 48/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4893\n",
            "Epoch 49/100\n",
            "214/214 [==============================] - 2s 8ms/step - loss: 0.4929\n",
            "Epoch 50/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 0.4907\n",
            "Epoch 51/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.4876\n",
            "Epoch 52/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4820\n",
            "Epoch 53/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4869\n",
            "Epoch 54/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4832\n",
            "Epoch 55/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4840\n",
            "Epoch 56/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4779\n",
            "Epoch 57/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4805\n",
            "Epoch 58/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4782\n",
            "Epoch 59/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4830\n",
            "Epoch 60/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4796\n",
            "Epoch 61/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4763\n",
            "Epoch 62/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4735\n",
            "Epoch 63/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4727\n",
            "Epoch 64/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4697\n",
            "Epoch 65/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4695\n",
            "Epoch 66/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4741\n",
            "Epoch 67/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4735\n",
            "Epoch 68/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4700\n",
            "Epoch 69/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4646\n",
            "Epoch 70/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4710\n",
            "Epoch 71/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.4670\n",
            "Epoch 72/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.4664\n",
            "Epoch 73/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.4658\n",
            "Epoch 74/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.4642\n",
            "Epoch 75/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.4686\n",
            "Epoch 76/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4642\n",
            "Epoch 77/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4642\n",
            "Epoch 78/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4667\n",
            "Epoch 79/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.4597\n",
            "Epoch 80/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4616\n",
            "Epoch 81/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4630\n",
            "Epoch 82/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4573\n",
            "Epoch 83/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4598\n",
            "Epoch 84/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4586\n",
            "Epoch 85/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4594\n",
            "Epoch 86/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4602\n",
            "Epoch 87/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4574\n",
            "Epoch 88/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4614\n",
            "Epoch 89/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4562\n",
            "Epoch 90/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4565\n",
            "Epoch 91/100\n",
            "214/214 [==============================] - 0s 2ms/step - loss: 0.4587\n",
            "Epoch 92/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4554\n",
            "Epoch 93/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4557\n",
            "Epoch 94/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.4575\n",
            "Epoch 95/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 0.4605\n",
            "Epoch 96/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 0.4566\n",
            "Epoch 97/100\n",
            "214/214 [==============================] - 1s 4ms/step - loss: 0.4550\n",
            "Epoch 98/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.4534\n",
            "Epoch 99/100\n",
            "214/214 [==============================] - 1s 2ms/step - loss: 0.4518\n",
            "Epoch 100/100\n",
            "214/214 [==============================] - 1s 3ms/step - loss: 0.4493\n",
            "54/54 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "LSTM Predicted Price: 247.22366333007812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "lstm_pred = lstm_model.predict(X_test_reshaped)\n",
        "lstm_mae = mean_absolute_error(y_test, lstm_pred)\n",
        "lstm_rmse = sqrt(mean_squared_error(y_test, lstm_pred))\n",
        "print(f\"MAE: {lstm_mae}\")\n",
        "print(f\"RMSE: {lstm_rmse}\")\n",
        "\n",
        "# Make predictions using LSTM for a new data point\n",
        "new_data_point_scaled = scaler.transform(new_data_point)\n",
        "new_data_point_reshaped = new_data_point_scaled.reshape(1, 1, new_data_point_scaled.shape[1])\n",
        "lstm_predicted_price = lstm_model.predict(new_data_point_reshaped)\n",
        "print(f\"LSTM Predicted Price: {lstm_predicted_price[0][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrZhANwxOSeH",
        "outputId": "682bd0e8-1a16-4ef9-a325-0516f7e5408b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54/54 [==============================] - 0s 6ms/step\n",
            "MAE: 0.41073272682174733\n",
            "RMSE: 0.7268212135172613\n",
            "1/1 [==============================] - 0s 172ms/step\n",
            "LSTM Predicted Price: 247.22366333007812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6zOmoARaO6Rl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}